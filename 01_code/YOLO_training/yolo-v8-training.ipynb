{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9109302,"sourceType":"datasetVersion","datasetId":5497841},{"sourceId":9132836,"sourceType":"datasetVersion","datasetId":5514390},{"sourceId":9190692,"sourceType":"datasetVersion","datasetId":5555894}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\n\nwandb.init(mode=\"disabled\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T11:40:01.295299Z","iopub.execute_input":"2024-08-17T11:40:01.295553Z","iopub.status.idle":"2024-08-17T11:40:03.904803Z","shell.execute_reply.started":"2024-08-17T11:40:01.295529Z","shell.execute_reply":"2024-08-17T11:40:03.903775Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-08-17T11:40:03.906411Z","iopub.execute_input":"2024-08-17T11:40:03.906779Z","iopub.status.idle":"2024-08-17T11:40:20.026804Z","shell.execute_reply.started":"2024-08-17T11:40:03.906755Z","shell.execute_reply":"2024-08-17T11:40:20.025860Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.2.78-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m615.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nDownloading ultralytics-8.2.78-py3-none-any.whl (869 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m869.0/869.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.2.78 ultralytics-thop-2.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-08-17T11:40:20.028131Z","iopub.execute_input":"2024-08-17T11:40:20.028420Z","iopub.status.idle":"2024-08-17T11:40:26.461409Z","shell.execute_reply.started":"2024-08-17T11:40:20.028396Z","shell.execute_reply":"2024-08-17T11:40:26.460603Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# train\nyolo = YOLO(\"yolov8n.pt\")\nresults = yolo.train(data=\"/kaggle/input/yolo-train-oxford/YOLO/yolo.yaml\", epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T11:40:26.463954Z","iopub.execute_input":"2024-08-17T11:40:26.464558Z","iopub.status.idle":"2024-08-17T12:26:58.887938Z","shell.execute_reply.started":"2024-08-17T11:40:26.464519Z","shell.execute_reply":"2024-08-17T12:26:58.887051Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 71.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.2.78 üöÄ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/input/yolo-train-oxford/YOLO/yolo.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 13.5MB/s]\n2024-08-17 11:40:29,029\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-08-17 11:40:30,384\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/yolo-train-oxford/YOLO/Training... 2163 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2163/2163 [00:08<00:00, 251.41it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/yolo-train-oxford/YOLO/Training/1736.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/yolo-train-oxford/YOLO/Training/1737.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/yolo-train-oxford/YOLO/Training/470.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/yolo-train-oxford/YOLO/Training/733.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/yolo-train-oxford/YOLO/Training/734.jpg: 1 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/yolo-train-oxford/YOLO is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/yolo-train-oxford/YOLO/Validation... 617 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 617/617 [00:02<00:00, 274.44it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/yolo-train-oxford/YOLO/Validation/1738.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/yolo-train-oxford/YOLO is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100      2.69G      2.231      1.942      1.423        118        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:31<00:00,  4.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:06<00:00,  3.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.513      0.609      0.576      0.224\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100       2.7G      1.844      1.452       1.25         66        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.683      0.701      0.759      0.326\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      2.89G      1.747      1.293      1.215         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.771      0.751      0.831      0.343\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100      2.59G      1.714      1.188      1.193         84        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.829      0.768      0.859      0.437\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100      2.92G      1.608      1.063      1.148         53        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.71it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.811      0.756      0.856      0.411\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100      2.72G       1.57     0.9866      1.133         80        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.877      0.813      0.911      0.514\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100      3.28G       1.52     0.9351      1.114         67        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.877      0.844      0.923      0.535\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      2.84G      1.495     0.8955      1.096         95        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.902      0.868       0.94      0.541\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100      2.62G      1.457     0.8658      1.081         58        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.911      0.874      0.947      0.532\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100      3.04G      1.443     0.8425      1.081         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.925      0.858      0.944      0.532\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100      2.92G      1.429      0.818      1.072         55        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.934      0.883      0.958      0.571\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100      2.77G      1.418     0.7961      1.055         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.922      0.895      0.958      0.583\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100      2.58G      1.383     0.7728       1.05         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.943      0.897      0.965      0.602\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100      3.13G       1.37     0.7559      1.038         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.925      0.894      0.954      0.594\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100      2.84G      1.371     0.7517      1.046         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.942      0.916       0.96      0.598\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100      2.84G      1.345     0.7313      1.033         68        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.947      0.912       0.97      0.609\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/100      2.94G      1.328     0.7212      1.023         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.98it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.951      0.909      0.972      0.617\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/100      2.78G       1.32     0.7123      1.024        116        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.954      0.911      0.972      0.625\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     19/100      2.58G      1.315     0.6985      1.026         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.954      0.922      0.975      0.624\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     20/100      2.76G      1.296     0.6861      1.013         69        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.966      0.923      0.979      0.629\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     21/100      2.93G       1.29     0.6737      1.006         92        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.77it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.954      0.926      0.976      0.633\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     22/100      2.97G      1.294     0.6778      1.006         72        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.963      0.927      0.979      0.642\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     23/100      3.07G      1.285     0.6665       1.01         80        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.958       0.93      0.976      0.637\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     24/100      3.13G      1.271     0.6566          1         68        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.965      0.936      0.981      0.649\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     25/100       3.1G      1.262     0.6534     0.9973         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.963      0.934       0.98      0.651\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     26/100      2.82G      1.268     0.6614      1.002         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.97it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.962      0.929       0.98      0.638\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     27/100       2.8G       1.26     0.6445      1.003         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.964      0.935      0.982      0.653\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     28/100      2.68G       1.25     0.6393      0.997         68        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.964      0.938      0.981      0.654\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     29/100      2.72G       1.25     0.6383     0.9925         48        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.968      0.933      0.983       0.66\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     30/100         3G      1.231     0.6204     0.9882         68        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495       0.97      0.937      0.982      0.648\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     31/100      2.58G      1.232      0.626     0.9931         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.965      0.945      0.985      0.664\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     32/100      2.51G      1.234     0.6156     0.9874         54        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.12it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.968       0.94      0.984      0.659\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     33/100      2.82G      1.217     0.6084     0.9801        110        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.963      0.949      0.985      0.666\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     34/100      2.94G      1.218     0.6076     0.9823         65        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.966      0.948      0.985      0.673\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     35/100      2.65G      1.214     0.6049     0.9823         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.969      0.938      0.983      0.667\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     36/100      3.03G      1.214     0.6051     0.9828         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.974       0.95      0.987      0.661\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     37/100      3.18G      1.207     0.6009     0.9806         64        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.962      0.939      0.982      0.652\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     38/100      2.66G        1.2     0.5995     0.9781         65        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.974      0.946      0.986      0.663\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     39/100      3.13G      1.198      0.592     0.9767         63        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.968       0.95      0.986      0.671\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     40/100      2.69G      1.188     0.5855     0.9713         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:03<00:00,  5.01it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.973      0.952      0.988      0.674\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     41/100      2.66G      1.199     0.5872     0.9759        106        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.99it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.974      0.954      0.988      0.685\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     42/100       3.1G      1.179     0.5793      0.967         77        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495       0.97      0.955      0.988      0.683\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     43/100      2.47G      1.176     0.5818     0.9669         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.978      0.947      0.987      0.679\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     44/100      2.72G      1.183     0.5778     0.9695         96        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.976      0.955      0.988       0.68\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     45/100      2.69G      1.174     0.5724     0.9646         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.972      0.956      0.988      0.674\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     46/100       2.9G      1.175     0.5743     0.9685         48        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.971      0.959      0.989      0.679\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     47/100      3.26G      1.169     0.5722     0.9643         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.976      0.961      0.989      0.689\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     48/100      3.29G      1.167     0.5652     0.9587         48        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.96it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.976      0.959      0.989      0.691\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     49/100      2.92G      1.161     0.5631     0.9601        117        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.974       0.96      0.989      0.686\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     50/100      3.18G      1.162     0.5637     0.9608         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.971      0.962      0.989      0.687\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     51/100      3.07G      1.162     0.5638     0.9639         54        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.979       0.96       0.99      0.687\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     52/100         3G      1.153     0.5578     0.9615        123        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.975      0.959      0.989      0.687\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     53/100      2.95G      1.153     0.5559     0.9601         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.974      0.959      0.989      0.688\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     54/100      2.86G      1.143     0.5509     0.9542         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.976      0.964       0.99      0.696\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     55/100      2.52G      1.143     0.5511     0.9532         53        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.978      0.956       0.99      0.695\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     56/100      3.11G      1.141     0.5518     0.9566         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495       0.98       0.96       0.99      0.694\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     57/100      2.87G      1.132     0.5386     0.9534         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.978      0.963       0.99      0.701\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     58/100      2.54G      1.137     0.5418     0.9528         62        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.23it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.977      0.965       0.99      0.692\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     59/100      2.96G       1.13     0.5423     0.9509         61        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.99it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.978      0.965      0.991      0.692\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     60/100      2.78G      1.131     0.5401      0.952         55        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.981      0.965      0.991      0.697\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     61/100      3.25G      1.125     0.5363     0.9504         51        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.979      0.967      0.991      0.699\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     62/100      2.71G      1.122     0.5338     0.9511         86        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.982      0.959       0.99        0.7\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     63/100      2.91G      1.125     0.5367     0.9502         54        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:03<00:00,  5.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.981      0.965      0.991      0.702\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     64/100      2.76G      1.115     0.5268     0.9432         75        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.978      0.968      0.992      0.703\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     65/100      3.12G      1.126       0.53     0.9486         53        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.983      0.963      0.991      0.701\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     66/100      2.64G      1.113     0.5271     0.9517         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.982      0.968      0.992      0.707\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     67/100      2.92G      1.115     0.5257     0.9444         82        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.96it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.964      0.992      0.705\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     68/100      3.21G      1.111      0.528     0.9417         76        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.978       0.97      0.991      0.708\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     69/100      2.73G      1.112     0.5242     0.9455         62        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.983      0.966      0.991      0.709\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     70/100      2.73G      1.111     0.5239     0.9418        117        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.968      0.992      0.709\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     71/100       3.1G      1.099     0.5159     0.9392        134        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495       0.98       0.97      0.991      0.706\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     72/100      2.94G      1.092     0.5138     0.9395         91        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.967      0.992      0.705\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     73/100      2.96G      1.099     0.5158     0.9402         71        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.969      0.992       0.71\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     74/100      2.88G      1.093     0.5139     0.9407         79        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.982       0.97      0.992      0.707\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     75/100      3.12G      1.091     0.5148     0.9389         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984       0.97      0.992      0.712\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     76/100      3.08G      1.092     0.5106     0.9397         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.982      0.971      0.992       0.71\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     77/100      2.97G      1.091     0.5085     0.9397         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.19it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.969      0.992      0.712\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     78/100      2.88G      1.081     0.5061      0.933         57        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984       0.97      0.992      0.716\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     79/100      2.81G      1.076     0.5016     0.9342         65        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.983       0.97      0.992      0.715\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     80/100      3.08G      1.081     0.5039     0.9331        117        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.966      0.992      0.715\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     81/100      2.41G      1.073     0.5013     0.9315         73        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.97it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.983      0.972      0.993      0.714\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     82/100      3.19G       1.07     0.4974     0.9335         67        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.987       0.97      0.992      0.715\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     83/100      2.84G       1.07     0.4973     0.9334         67        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.77it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.987       0.97      0.993      0.719\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     84/100      2.81G      1.067     0.4953     0.9297         80        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.973      0.993      0.718\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     85/100      2.67G      1.068     0.4951     0.9305        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.62it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.972      0.993      0.716\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     86/100      2.71G       1.06     0.4926     0.9282         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.987      0.971      0.993       0.72\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     87/100      2.93G      1.063     0.4921     0.9297         98        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:21<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.974      0.993      0.718\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     88/100       2.8G       1.06     0.4898     0.9321         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.97it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.983      0.974      0.992      0.718\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     89/100      2.91G      1.055     0.4892     0.9266         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.987      0.973      0.993       0.72\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     90/100       2.7G      1.059      0.492     0.9288        112        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:22<00:00,  6.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.80it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.984      0.973      0.993      0.722\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     91/100      2.38G      1.063     0.4626     0.9477         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:25<00:00,  5.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.974      0.993       0.72\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     92/100      2.21G      1.034     0.4487     0.9373         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.53it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.976      0.993      0.724\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     93/100      2.17G       1.03     0.4447     0.9366         45        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.53it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.986      0.976      0.993      0.726\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     94/100       2.2G      1.027     0.4454     0.9379         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.50it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.987      0.976      0.993      0.726\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     95/100      2.18G      1.027     0.4431     0.9334         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.51it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.974      0.993      0.728\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     96/100      2.21G      1.024     0.4421     0.9342         42        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.52it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.75it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.987      0.975      0.993      0.728\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     97/100       2.2G      1.017     0.4385     0.9313         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.50it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.97it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.977      0.993      0.726\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     98/100      2.18G      1.017     0.4381     0.9314         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.53it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.978      0.993      0.726\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     99/100       2.2G      1.014     0.4371     0.9312         54        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.52it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.985      0.977      0.993      0.727\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"    100/100      2.19G       1.01     0.4355     0.9294         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 136/136 [00:20<00:00,  6.48it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:04<00:00,  4.97it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.986      0.976      0.993      0.729\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n100 epochs completed in 0.755 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics YOLOv8.2.78 üöÄ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\nModel summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:15<00:00,  1.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        617       9495      0.986      0.976      0.993      0.729\nSpeed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 1.7ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"yolo_trained = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n#yolo_trained = YOLO(\"yolov8n.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T12:50:33.202712Z","iopub.execute_input":"2024-08-17T12:50:33.203642Z","iopub.status.idle":"2024-08-17T12:50:33.267401Z","shell.execute_reply.started":"2024-08-17T12:50:33.203601Z","shell.execute_reply":"2024-08-17T12:50:33.266524Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def count_people_from_labels(label_path):\n    person_count = 0\n    \n    # Open the label file and count entries where class_id is 0 (person)\n    with open(label_path, 'r') as file:\n        for line in file:\n            class_id = int(line.split()[0])\n            if class_id == 0:  # 0 is the class ID for 'person'\n                person_count += 1\n    \n    return person_count\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T12:50:33.830190Z","iopub.execute_input":"2024-08-17T12:50:33.830533Z","iopub.status.idle":"2024-08-17T12:50:33.836098Z","shell.execute_reply.started":"2024-08-17T12:50:33.830500Z","shell.execute_reply":"2024-08-17T12:50:33.835043Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport os\nimport numpy as np\ndef count_people_from_yolo(image_path):\n    # Load the image\n    img = Image.open(image_path)\n    \n    # Get the detections directly\n    results = yolo_trained.predict(img)\n    boxes = results[0].boxes.xyxy.tolist()\n    classes = results[0].boxes.cls.tolist()\n    detections = np.hstack((boxes,np.array(classes).reshape(-1, 1)))\n    \n    # Count the number of people detected\n    person_count = 0\n    for det in detections:\n        class_id = int(det[-1])\n        if class_id == 0:  # YOLO class ID for 'person' is 0\n            person_count += 1\n    \n    return person_count","metadata":{"execution":{"iopub.status.busy":"2024-08-17T12:50:34.509514Z","iopub.execute_input":"2024-08-17T12:50:34.509841Z","iopub.status.idle":"2024-08-17T12:50:34.516602Z","shell.execute_reply.started":"2024-08-17T12:50:34.509813Z","shell.execute_reply":"2024-08-17T12:50:34.515710Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def count_people_from_yolo(image_path):\n    # Load the image\n    img = Image.open(image_path)\n    \n    # Perform inference (assuming `yolo_trained` is your YOLO model's inference function)\n    results = yolo_trained(img)\n    \n    # Extract bounding boxes and class labels\n    boxes = results[0].boxes.xyxy.tolist()  # 2D list: each sublist is [x1, y1, x2, y2]\n    classes = results[0].boxes.cls.tolist()  # 1D list of class IDs\n    \n    if len(boxes) == 0 or len(classes) == 0:\n        return 0  # Return 0 if no detections are found\n    \n    #if len(boxes) != len(classes):\n     #   raise ValueError(\"Number of boxes and classes do not match.\")\n    \n    # Convert classes to 2D array for hstack\n    classes = np.array(classes).reshape(-1, 1)\n\n    # Stack boxes and class IDs\n    detections = np.hstack((boxes, classes))\n    \n    # Count the number of people detected (YOLO class ID for 'person' is 0)\n    person_count = sum(int(det[-1]) == 0 for det in detections)\n    \n    return person_count","metadata":{"execution":{"iopub.status.busy":"2024-08-17T12:50:35.060470Z","iopub.execute_input":"2024-08-17T12:50:35.060800Z","iopub.status.idle":"2024-08-17T12:50:35.067922Z","shell.execute_reply.started":"2024-08-17T12:50:35.060762Z","shell.execute_reply":"2024-08-17T12:50:35.066927Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"folder = '/kaggle/input/yolo-train-oxford/YOLO/Testing'\n\nactual_counts = []\npredicted_counts = []\n\nfor filename in os.listdir(folder):\n    # Process only .jpg files\n    if filename.endswith('.jpg'):\n        # Get corresponding image and label paths\n        image_path = os.path.join(folder, filename)\n        label_path = os.path.join(folder, os.path.splitext(filename)[0] + '.txt')\n        \n        # Ensure the label file exists\n        if os.path.exists(label_path):\n            # Count people based on labels (ground truth)\n            actual_count = count_people_from_labels(label_path)\n            \n            # Count people using YOLO model\n            predicted_count = count_people_from_yolo(image_path)\n            \n            # Store the counts\n            actual_counts.append(actual_count)\n            predicted_counts.append(predicted_count)\n            \n            print(f\"{filename}: Actual = {actual_count}, Predicted = {predicted_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T12:50:35.443859Z","iopub.execute_input":"2024-08-17T12:50:35.444442Z","iopub.status.idle":"2024-08-17T12:50:42.109759Z","shell.execute_reply.started":"2024-08-17T12:50:35.444413Z","shell.execute_reply":"2024-08-17T12:50:42.108920Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\n0: 640x640 23 persons, 8.4ms\nSpeed: 3.0ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n623.jpg: Actual = 20, Predicted = 23\n\n0: 640x640 19 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n771.jpg: Actual = 17, Predicted = 19\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2029.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 26 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1385.jpg: Actual = 25, Predicted = 26\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n333.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n537.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n654.jpg: Actual = 20, Predicted = 21\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1339.jpg: Actual = 21, Predicted = 21\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2057.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2137.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n6.jpg: Actual = 13, Predicted = 15\n\n0: 640x640 19 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n708.jpg: Actual = 19, Predicted = 19\n\n0: 640x640 22 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1840.jpg: Actual = 19, Predicted = 22\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2580.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n501.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2279.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 18 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n576.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 28 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1451.jpg: Actual = 27, Predicted = 28\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n189.jpg: Actual = 8, Predicted = 9\n\n0: 640x640 15 persons, 7.4ms\nSpeed: 1.9ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2403.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2626.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 19 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1815.jpg: Actual = 20, Predicted = 19\n\n0: 640x640 10 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n131.jpg: Actual = 10, Predicted = 10\n\n0: 640x640 10 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1058.jpg: Actual = 9, Predicted = 10\n\n0: 640x640 13 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n892.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2476.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 13 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2795.jpg: Actual = 12, Predicted = 13\n\n0: 640x640 12 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n283.jpg: Actual = 12, Predicted = 12\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n359.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 19 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1709.jpg: Actual = 18, Predicted = 19\n\n0: 640x640 12 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n289.jpg: Actual = 12, Predicted = 12\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2842.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 7 persons, 7.3ms\nSpeed: 2.5ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2890.jpg: Actual = 6, Predicted = 7\n\n0: 640x640 12 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n295.jpg: Actual = 12, Predicted = 12\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2592.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 2.0ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n829.jpg: Actual = 15, Predicted = 16\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 2.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2694.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 12 persons, 7.6ms\nSpeed: 1.8ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n291.jpg: Actual = 12, Predicted = 12\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1778.jpg: Actual = 19, Predicted = 20\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n2503.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2840.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n665.jpg: Actual = 19, Predicted = 21\n\n0: 640x640 18 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1183.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 6 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2900.jpg: Actual = 6, Predicted = 6\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2661.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 18 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n589.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1108.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 12 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n35.jpg: Actual = 12, Predicted = 12\n\n0: 640x640 7 persons, 7.3ms\nSpeed: 2.1ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2944.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2109.jpg: Actual = 13, Predicted = 15\n\n0: 640x640 7 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2951.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 23 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1366.jpg: Actual = 23, Predicted = 23\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2671.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n601.jpg: Actual = 18, Predicted = 20\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2850.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1997.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 13 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2541.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 8 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n230.jpg: Actual = 9, Predicted = 8\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n872.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 18 persons, 7.5ms\nSpeed: 1.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2352.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3047.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1919.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 20 persons, 8.5ms\nSpeed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n538.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 13 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n57.jpg: Actual = 9, Predicted = 13\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n227.jpg: Actual = 10, Predicted = 9\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1095.jpg: Actual = 14, Predicted = 16\n\n0: 640x640 8 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n3054.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n374.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1962.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2614.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 8 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3006.jpg: Actual = 7, Predicted = 8\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n701.jpg: Actual = 19, Predicted = 20\n\n0: 640x640 22 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1767.jpg: Actual = 19, Predicted = 22\n\n0: 640x640 28 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1544.jpg: Actual = 28, Predicted = 28\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1324.jpg: Actual = 21, Predicted = 21\n\n0: 640x640 27 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1523.jpg: Actual = 24, Predicted = 27\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1259.jpg: Actual = 21, Predicted = 21\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2310.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n2296.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n186.jpg: Actual = 8, Predicted = 9\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n69.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 17 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n414.jpg: Actual = 17, Predicted = 17\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1980.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2822.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 28 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1503.jpg: Actual = 25, Predicted = 28\n\n0: 640x640 23 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1287.jpg: Actual = 21, Predicted = 23\n\n0: 640x640 12 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n943.jpg: Actual = 10, Predicted = 12\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n535.jpg: Actual = 20, Predicted = 21\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n393.jpg: Actual = 14, Predicted = 16\n\n0: 640x640 9 persons, 7.2ms\nSpeed: 1.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1053.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 27 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1462.jpg: Actual = 27, Predicted = 27\n\n0: 640x640 11 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n276.jpg: Actual = 11, Predicted = 11\n\n0: 640x640 16 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2382.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 13 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n903.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 21 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n716.jpg: Actual = 18, Predicted = 21\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1901.jpg: Actual = 16, Predicted = 15\n\n0: 640x640 13 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2534.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 18 persons, 7.2ms\nSpeed: 1.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n574.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 11 persons, 7.2ms\nSpeed: 2.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n44.jpg: Actual = 11, Predicted = 11\n\n0: 640x640 22 persons, 7.1ms\nSpeed: 2.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1839.jpg: Actual = 19, Predicted = 22\n\n0: 640x640 18 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n561.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 26 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1550.jpg: Actual = 28, Predicted = 26\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2140.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 15 persons, 7.2ms\nSpeed: 2.3ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2450.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2594.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 9 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2829.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 8 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n179.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 21 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1261.jpg: Actual = 22, Predicted = 21\n\n0: 640x640 17 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n419.jpg: Actual = 17, Predicted = 17\n\n0: 640x640 8 persons, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1038.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 22 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1353.jpg: Actual = 22, Predicted = 22\n\n0: 640x640 22 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1290.jpg: Actual = 21, Predicted = 22\n\n0: 640x640 14 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n317.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 16 persons, 7.1ms\nSpeed: 2.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2101.jpg: Actual = 14, Predicted = 16\n\n0: 640x640 19 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1816.jpg: Actual = 20, Predicted = 19\n\n0: 640x640 10 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n145.jpg: Actual = 9, Predicted = 10\n\n0: 640x640 16 persons, 7.1ms\nSpeed: 1.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2064.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 13 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n23.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2401.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 14 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2787.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2736.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 16 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2102.jpg: Actual = 14, Predicted = 16\n\n0: 640x640 7 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n166.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 23 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1730.jpg: Actual = 21, Predicted = 23\n\n0: 640x640 20 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n430.jpg: Actual = 18, Predicted = 20\n\n0: 640x640 28 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1450.jpg: Actual = 27, Predicted = 28\n\n0: 640x640 17 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2344.jpg: Actual = 17, Predicted = 17\n\n0: 640x640 21 persons, 7.1ms\nSpeed: 1.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1754.jpg: Actual = 19, Predicted = 21\n\n0: 640x640 20 persons, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1244.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 19 persons, 7.1ms\nSpeed: 2.0ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1684.jpg: Actual = 18, Predicted = 19\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2613.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 16 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1140.jpg: Actual = 17, Predicted = 16\n\n0: 640x640 7 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n2885.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 18 persons, 7.2ms\nSpeed: 1.8ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n809.jpg: Actual = 17, Predicted = 18\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2723.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 14 persons, 7.2ms\nSpeed: 1.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2118.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 8 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n174.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2136.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 6 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2889.jpg: Actual = 6, Predicted = 6\n\n0: 640x640 18 persons, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n854.jpg: Actual = 14, Predicted = 18\n\n0: 640x640 18 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2098.jpg: Actual = 14, Predicted = 18\n\n0: 640x640 6 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n3018.jpg: Actual = 6, Predicted = 6\n\n0: 640x640 14 persons, 7.1ms\nSpeed: 1.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n332.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 26 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1529.jpg: Actual = 26, Predicted = 26\n\n0: 640x640 19 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n784.jpg: Actual = 18, Predicted = 19\n\n0: 640x640 21 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n633.jpg: Actual = 20, Predicted = 21\n\n0: 640x640 15 persons, 7.2ms\nSpeed: 2.2ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2240.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 7 persons, 7.1ms\nSpeed: 2.4ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2939.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 19 persons, 7.1ms\nSpeed: 1.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1627.jpg: Actual = 20, Predicted = 19\n\n0: 640x640 12 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n48.jpg: Actual = 11, Predicted = 12\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2760.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 14 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n918.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 15 persons, 7.2ms\nSpeed: 1.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2187.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 18 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n572.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 7 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n169.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 21 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1743.jpg: Actual = 21, Predicted = 21\n\n0: 640x640 19 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n821.jpg: Actual = 15, Predicted = 19\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.9ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2744.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 17 persons, 7.1ms\nSpeed: 2.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2374.jpg: Actual = 16, Predicted = 17\n\n0: 640x640 9 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3080.jpg: Actual = 8, Predicted = 9\n\n0: 640x640 9 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3035.jpg: Actual = 8, Predicted = 9\n\n0: 640x640 10 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n88.jpg: Actual = 10, Predicted = 10\n\n0: 640x640 28 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1469.jpg: Actual = 25, Predicted = 28\n\n0: 640x640 22 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1345.jpg: Actual = 22, Predicted = 22\n\n0: 640x640 21 persons, 7.0ms\nSpeed: 2.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1797.jpg: Actual = 20, Predicted = 21\n\n0: 640x640 16 persons, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2380.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 9 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n148.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 7 persons, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2949.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 18 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n693.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 18 persons, 7.2ms\nSpeed: 1.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1879.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 21 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1722.jpg: Actual = 19, Predicted = 21\n\n0: 640x640 19 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n650.jpg: Actual = 20, Predicted = 19\n\n0: 640x640 16 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2324.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 14 persons, 7.2ms\nSpeed: 1.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1917.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2024.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 23 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1368.jpg: Actual = 22, Predicted = 23\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2407.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 15 persons, 7.2ms\nSpeed: 1.8ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2663.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 20 persons, 7.2ms\nSpeed: 1.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n667.jpg: Actual = 19, Predicted = 20\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1107.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 8 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1035.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 11 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n940.jpg: Actual = 11, Predicted = 11\n\n0: 640x640 23 persons, 7.8ms\nSpeed: 1.8ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1362.jpg: Actual = 23, Predicted = 23\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2138.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 21 persons, 7.1ms\nSpeed: 2.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1765.jpg: Actual = 19, Predicted = 21\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2058.jpg: Actual = 16, Predicted = 15\n\n0: 640x640 26 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1397.jpg: Actual = 26, Predicted = 26\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2578.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 13 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2509.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 10 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1068.jpg: Actual = 10, Predicted = 10\n\n0: 640x640 8 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2990.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 13 persons, 7.0ms\nSpeed: 1.9ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n911.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 10 persons, 7.4ms\nSpeed: 1.8ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n957.jpg: Actual = 9, Predicted = 10\n\n0: 640x640 21 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n802.jpg: Actual = 18, Predicted = 21\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n321.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1121.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 10 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n956.jpg: Actual = 9, Predicted = 10\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2095.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2754.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 6 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2912.jpg: Actual = 6, Predicted = 6\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n889.jpg: Actual = 12, Predicted = 14\n\n0: 640x640 28 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1454.jpg: Actual = 27, Predicted = 28\n\n0: 640x640 8 persons, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n183.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 25 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1588.jpg: Actual = 23, Predicted = 25\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2466.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 19 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n459.jpg: Actual = 20, Predicted = 19\n\n0: 640x640 6 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2908.jpg: Actual = 6, Predicted = 6\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 1.9ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2726.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 16 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1098.jpg: Actual = 14, Predicted = 16\n\n0: 640x640 10 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1000.jpg: Actual = 9, Predicted = 10\n\n0: 640x640 24 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1585.jpg: Actual = 24, Predicted = 24\n\n0: 640x640 14 persons, 8.1ms\nSpeed: 2.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2516.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 19 persons, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n557.jpg: Actual = 18, Predicted = 19\n\n0: 640x640 20 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n1237.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 12 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1950.jpg: Actual = 14, Predicted = 12\n\n0: 640x640 25 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1481.jpg: Actual = 25, Predicted = 25\n\n0: 640x640 16 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2291.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 19 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1843.jpg: Actual = 18, Predicted = 19\n\n0: 640x640 16 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n840.jpg: Actual = 15, Predicted = 16\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2634.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 13 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n11.jpg: Actual = 14, Predicted = 13\n\n0: 640x640 18 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2357.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 22 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n652.jpg: Actual = 20, Predicted = 22\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2759.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2126.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 9 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3045.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 20 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n472.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 12 persons, 7.0ms\nSpeed: 1.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n34.jpg: Actual = 12, Predicted = 12\n\n0: 640x640 27 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1415.jpg: Actual = 27, Predicted = 27\n\n0: 640x640 20 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n432.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 11 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1070.jpg: Actual = 10, Predicted = 11\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2013.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 9 persons, 7.0ms\nSpeed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3033.jpg: Actual = 8, Predicted = 9\n\n0: 640x640 22 persons, 7.0ms\nSpeed: 2.3ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n1305.jpg: Actual = 22, Predicted = 22\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n21.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 25 persons, 8.4ms\nSpeed: 2.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1597.jpg: Actual = 24, Predicted = 25\n\n0: 640x640 15 persons, 7.0ms\nSpeed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2409.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 16 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2422.jpg: Actual = 15, Predicted = 16\n\n0: 640x640 19 persons, 7.0ms\nSpeed: 1.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1847.jpg: Actual = 18, Predicted = 19\n\n0: 640x640 17 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2430.jpg: Actual = 16, Predicted = 17\n\n0: 640x640 17 persons, 7.9ms\nSpeed: 2.6ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n855.jpg: Actual = 14, Predicted = 17\n\n0: 640x640 18 persons, 7.1ms\nSpeed: 1.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2350.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 13 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2546.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 14 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2502.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 8 persons, 7.0ms\nSpeed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n3032.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 21 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n657.jpg: Actual = 19, Predicted = 21\n\n0: 640x640 7 persons, 7.0ms\nSpeed: 1.8ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2943.jpg: Actual = 7, Predicted = 7\n\n0: 640x640 16 persons, 7.0ms\nSpeed: 1.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n348.jpg: Actual = 16, Predicted = 16\n\n0: 640x640 14 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1941.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 15 persons, 7.1ms\nSpeed: 1.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2402.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 13 persons, 7.1ms\nSpeed: 2.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2032.jpg: Actual = 13, Predicted = 13\n\n0: 640x640 14 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n923.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 14 persons, 7.1ms\nSpeed: 1.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1952.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 17 persons, 10.8ms\nSpeed: 2.2ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n413.jpg: Actual = 17, Predicted = 17\n\n0: 640x640 22 persons, 7.5ms\nSpeed: 2.8ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1275.jpg: Actual = 22, Predicted = 22\n\n0: 640x640 9 persons, 9.9ms\nSpeed: 2.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n2819.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 20 persons, 11.0ms\nSpeed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1830.jpg: Actual = 19, Predicted = 20\n\n0: 640x640 18 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1699.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 23 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1723.jpg: Actual = 20, Predicted = 23\n\n0: 640x640 21 persons, 8.2ms\nSpeed: 1.8ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n522.jpg: Actual = 21, Predicted = 21\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n325.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 6 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2906.jpg: Actual = 6, Predicted = 6\n\n0: 640x640 29 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1438.jpg: Actual = 27, Predicted = 29\n\n0: 640x640 24 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n1623.jpg: Actual = 21, Predicted = 24\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n471.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 22 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1306.jpg: Actual = 22, Predicted = 22\n\n0: 640x640 17 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2371.jpg: Actual = 16, Predicted = 17\n\n0: 640x640 23 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n1365.jpg: Actual = 23, Predicted = 23\n\n0: 640x640 26 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1403.jpg: Actual = 26, Predicted = 26\n\n0: 640x640 7 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2930.jpg: Actual = 6, Predicted = 7\n\n0: 640x640 12 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n47.jpg: Actual = 12, Predicted = 12\n\n0: 640x640 8 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3048.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 6 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n3020.jpg: Actual = 6, Predicted = 6\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n857.jpg: Actual = 13, Predicted = 16\n\n0: 640x640 27 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1444.jpg: Actual = 26, Predicted = 27\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n324.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n1246.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2617.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n2007.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 18 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2359.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2124.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 20 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1226.jpg: Actual = 20, Predicted = 20\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1811.jpg: Actual = 20, Predicted = 21\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2215.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 27 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1516.jpg: Actual = 25, Predicted = 27\n\n0: 640x640 19 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1633.jpg: Actual = 19, Predicted = 19\n\n0: 640x640 23 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1367.jpg: Actual = 23, Predicted = 23\n\n0: 640x640 8 persons, 7.3ms\nSpeed: 2.0ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3069.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 22 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1732.jpg: Actual = 21, Predicted = 22\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n899.jpg: Actual = 13, Predicted = 14\n\n0: 640x640 26 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1587.jpg: Actual = 24, Predicted = 26\n\n0: 640x640 10 persons, 7.3ms\nSpeed: 2.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n969.jpg: Actual = 10, Predicted = 10\n\n0: 640x640 17 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1147.jpg: Actual = 17, Predicted = 17\n\n0: 640x640 26 persons, 7.3ms\nSpeed: 2.3ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1578.jpg: Actual = 24, Predicted = 26\n\n0: 640x640 22 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1321.jpg: Actual = 21, Predicted = 22\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2234.jpg: Actual = 15, Predicted = 15\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n881.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 9 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n986.jpg: Actual = 9, Predicted = 9\n\n0: 640x640 18 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n593.jpg: Actual = 18, Predicted = 18\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2586.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n551.jpg: Actual = 19, Predicted = 21\n\n0: 640x640 21 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n1323.jpg: Actual = 21, Predicted = 21\n\n0: 640x640 15 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2198.jpg: Actual = 14, Predicted = 15\n\n0: 640x640 8 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n3070.jpg: Actual = 8, Predicted = 8\n\n0: 640x640 19 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n461.jpg: Actual = 20, Predicted = 19\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2212.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 14 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n2461.jpg: Actual = 14, Predicted = 14\n\n0: 640x640 10 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n2861.jpg: Actual = 10, Predicted = 10\n\n0: 640x640 10 persons, 7.3ms\nSpeed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n90.jpg: Actual = 10, Predicted = 10\n\n0: 640x640 16 persons, 7.3ms\nSpeed: 1.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n1979.jpg: Actual = 15, Predicted = 16\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_absolute_error\n\nr2 = r2_score(actual_counts, predicted_counts)\nmae = mean_absolute_error(actual_counts, predicted_counts)\n\nprint(f'R¬≤: {r2}')\nprint(f'MAE: {mae}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T12:50:42.111649Z","iopub.execute_input":"2024-08-17T12:50:42.112086Z","iopub.status.idle":"2024-08-17T12:50:42.118813Z","shell.execute_reply.started":"2024-08-17T12:50:42.112051Z","shell.execute_reply":"2024-08-17T12:50:42.117852Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"R¬≤: 0.9530484179401887\nMAE: 0.6290322580645161\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}